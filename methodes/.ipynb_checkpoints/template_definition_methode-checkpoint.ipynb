{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from sklearn.linear_model import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class ClassifieurLineaire:\n",
    "    def __init__(self, lamb, methode):\n",
    "        \"\"\"\n",
    "        Algorithmes de classification lineaire\n",
    "\n",
    "        L'argument ``lamb`` est une constante pour régulariser la magnitude\n",
    "        des poids w et w_0\n",
    "\n",
    "        ``methode`` :   1 pour classification generative\n",
    "                        2 pour Perceptron\n",
    "                        3 pour Perceptron sklearn\n",
    "        \"\"\"\n",
    "        self.w = np.array([1., 2.])  # paramètre aléatoire\n",
    "        self.w_0 = -5.              # paramètre aléatoire\n",
    "        self.lamb = lamb\n",
    "        self.methode = methode\n",
    "\n",
    "    # def entrainement(self, x_train, t_train):\n",
    "        \n",
    "\n",
    "    def prediction(self, x):\n",
    "        \"\"\"\n",
    "        Retourne la prédiction du classifieur lineaire.  Retourne 1 si x est\n",
    "        devant la frontière de décision et 0 sinon.\n",
    "\n",
    "        ``x`` est un tableau 1D Numpy\n",
    "\n",
    "        Cette méthode suppose que la méthode ``entrainement()``\n",
    "        a préalablement été appelée. Elle doit utiliser les champs ``self.w``\n",
    "        et ``self.w_0`` afin de faire cette classification.\n",
    "        \"\"\"\n",
    "        pred = np.dot(np.transpose(self.w), x) + self.w_0\n",
    "        if pred < 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    @staticmethod\n",
    "    def erreur(t, prediction):\n",
    "        \"\"\"\n",
    "        Retourne l'erreur de classification, i.e.\n",
    "        1. si la cible ``t`` et la prédiction ``prediction``\n",
    "        sont différentes, 0. sinon.\n",
    "        \"\"\"\n",
    "        if t == prediction:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def afficher_donnees_et_modele(self, x_train, t_train, x_test, t_test):\n",
    "        \"\"\"\n",
    "        afficher les donnees et le modele\n",
    "\n",
    "        x_train, t_train : donnees d'entrainement\n",
    "        x_test, t_test : donnees de test\n",
    "        \"\"\"\n",
    "        plt.figure(0)\n",
    "        plt.scatter(x_train[:, 0], x_train[:, 1],\n",
    "                    s=t_train * 100 + 20, c=t_train)\n",
    "\n",
    "        pente = -self.w[0] / self.w[1]\n",
    "        xx = np.linspace(np.min(x_test[:, 0]) - 2, np.max(x_test[:, 0]) + 2)\n",
    "        yy = pente * xx - self.w_0 / self.w[1]\n",
    "        plt.plot(xx, yy)\n",
    "        plt.title('Training data')\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.scatter(x_test[:, 0], x_test[:, 1], s=t_test * 100 + 20, c=t_test)\n",
    "\n",
    "        pente = -self.w[0] / self.w[1]\n",
    "        xx = np.linspace(np.min(x_test[:, 0]) - 2, np.max(x_test[:, 0]) + 2)\n",
    "        yy = pente * xx - self.w_0 / self.w[1]\n",
    "        plt.plot(xx, yy)\n",
    "        plt.title('Testing data')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def parametres(self):\n",
    "        \"\"\"\n",
    "        Retourne les paramètres du modèle\n",
    "        \"\"\"\n",
    "        return self.w_0, self.w\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "02f2ccd4fe1ad32793ffe122d79ad14ef1f70e18212fddcdc0326ef17b61a4a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
